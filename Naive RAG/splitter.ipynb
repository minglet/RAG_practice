{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter를 사용해보고 어떻게 나누어지는지 결과 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 기반 Splitter\n",
    "- CharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Splitter에 대해서 공부하고 있습니다. \\nCharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수',\n",
       " '사이즈와 청크 오버랩을 설정할 수 있습니다.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 고정된 크기의 chunk_size를 가지는 Splitter 생성\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",  # 공백 단위로 분리 (\"\\n\", \"\\n\\n\"등으로 분리 가능)\n",
    "    chunk_size=100,  # 각 청크의 최대 문자 수\n",
    "    chunk_overlap=20  # 청크 간 겹치는 문자 수\n",
    ")\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\"\"\"\n",
    "\n",
    "# 텍스트를 청크로 분리\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Splitter에 대해서 공부하고 있습니다.',\n",
       " 'CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 20\n",
    ")\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\"\"\"\n",
    "\n",
    "# 텍스트를 청크로 분리\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Splitter에 대해서 공부하고 있습니다. \\nCharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama index SecntenceSplitter\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\"\"\"\n",
    "\n",
    "# 텍스트를 청크로 분리\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰 기반 Splitter\n",
    "- TokenTextSplitter\n",
    "- SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Splitter에 대해서 공부하고 있습니다. \\nCharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사',\n",
       " ' 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\\nSentenceSplitter는 문장과 단락을 유지하',\n",
       " '�과 단락을 유지하면서 청크를 나누는 splitter입니다.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TokenTextSplitter\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    "    )\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\n",
    "SentenceSplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.\"\"\"\n",
    "\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/rag_poc/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['splitter에 대해서 공부하고 [UNK]. charactertextsplitter는 character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 [UNK]. sentencesplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentenceTransformersTokenTextSplitter\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\n",
    "SentenceSplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.\"\"\"\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글을 지원하는 konlpy 사용하기\n",
    "- 아래의 코드를 실행하기 전에 `pip install konlpy` 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Splitter에 대해서 공부하고 있습니다.',\n",
       " 'CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.',\n",
       " 'SentenceSplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter 입니다.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "from langchain_text_splitters import KonlpyTextSplitter\n",
    "\n",
    "text_splitter = KonlpyTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap=20\n",
    "    )\n",
    "\n",
    "# 예제 텍스트\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\n",
    "SentenceSplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.\"\"\"\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face에서 (한글 지원하는) tokenizer를 불러와서 Splitter로 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad866ddcd0e47d480352914c447deff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa511ea1614285880e01ce35779fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff0b8beeaa5437aa4cd2b03ae63668c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['splitter에 대해서 공부하고 [UNK]. charactertextsplitter는 character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 [UNK]. sentencesplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.']\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 한글 지원 토크나이저 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
    "\n",
    "# 토큰 기준 Splitter 생성 - from_huggingface_tokenizer를 통해 tokenizer 넣어주기\n",
    "text_splitter = SentenceTransformersTokenTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=10,  # 청크 크기 (토큰 수)\n",
    "    chunk_overlap=3  # 청크 간 겹침 (토큰 수)\n",
    ")\n",
    "\n",
    "example_text = \"\"\"Splitter에 대해서 공부하고 있습니다. \n",
    "CharacterTextSplitter는 Character를 기준으로 청크를 나누는 방법이며, 청크 사이즈와 청크 오버랩을 설정할 수 있습니다.\n",
    "SentenceSplitter는 문장과 단락을 유지하면서 청크를 나누는 splitter입니다.\"\"\"\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(example_text)\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구조 기반 Splitter\n",
    "- MarkdownHeaderTextSplitter \n",
    "- HTMLHeaderTextSplitter\n",
    "- code split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Title', 'Header 2': '1. SubTitle'}, page_content='Hi this is Jim\\nHi this is Joe'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': '1. SubTitle', 'Header 3': '1-1. Sub-SubTitle'}, page_content='Hi this is Lance'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': '2. Baz'}, page_content='Hi this is Molly')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# 마크다운 형식의 문서를 문자열로 정의\n",
    "markdown_document = \"\"\"\n",
    "# Title\n",
    "## 1. SubTitle\n",
    "Hi this is Jim\n",
    "Hi this is Joe\n",
    "### 1-1. Sub-SubTitle\n",
    "Hi this is Lance \n",
    "## 2. Baz\n",
    "Hi this is Molly\n",
    "\"\"\"\n",
    "\n",
    "chunks = text_splitter.split_text(markdown_document)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Header 1': '제목 1'}, page_content='이것은 첫 번째 단락입니다.'), Document(metadata={'Header 1': '제목 1', 'Header 2': '제목 2'}, page_content='이것은 두 번째 단락입니다.  \\n리스트 항목 1 리스트 항목 2')]\n"
     ]
    }
   ],
   "source": [
    "# HTMLTextSplitter\n",
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "# HTML 기반 Splitter\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# 예제 HTML 텍스트\n",
    "example_html = \"\"\"\n",
    "<h1>제목 1</h1>\n",
    "<p>이것은 첫 번째 단락입니다.</p>\n",
    "<h2>제목 2</h2>\n",
    "<p>이것은 두 번째 단락입니다.</p>\n",
    "<ul>\n",
    "    <li>리스트 항목 1</li>\n",
    "    <li>리스트 항목 2</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "# 텍스트 분리\n",
    "chunks = html_splitter.split_text(example_html)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No two El Niño winters are the same, but many have temperature and precipitation trends in common.  \n",
      "Average conditions during an El Niño winter across the continental US.  \n",
      "One of the major reasons is the position of the jet stream, which often shifts south during an El Niño winter. This shift typically brings wetter and cooler weather to the South while the North becomes drier and warmer, according to NOAA.  \n",
      "Because the jet stream is essentially a river of air that storms flow through, they c\n"
     ]
    }
   ],
   "source": [
    "# HTMLTextSplitter를 url를 불러서 \n",
    "url = \"https://www.cnn.com/2023/09/25/weather/el-nino-winter-us-climate/index.html\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "print(html_header_splits[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의미 기반 Splitter\n",
    "- SemanticChunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
